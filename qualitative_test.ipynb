{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importovanie kniznic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "from chatbot.gemini_embdeddings import gemini_embdeddings_create\n",
    "from chatbot.gpt_embdeddings import openai_embedding_create\n",
    "import random\n",
    "import textwrap\n",
    "import re \n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate import meteor_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Funkcia na vypocet bert score , pomocou kniznice BERTscorer\n",
    "def bert_score(answer,expected_answer):\n",
    "    from bert_score import BERTScorer\n",
    "    scorer = BERTScorer(lang=\"sk\")\n",
    "    P1, R1, F1_1 = scorer.score([answer], [expected_answer])\n",
    "    return F1_1.tolist()[0]\n",
    "\n",
    "\n",
    "#Táto funkcia používa embdeddings modely  na premenu textu na číselné reprezentacie slov a potom vypočíta kosínusovú podobnosť medzi týmito embeddings, aby zistila, ako podobné sú dva vstupy.\n",
    "def create_embdeddings_similarity(otazka1,otazka2):\n",
    "    # Vytvorí embeddings pre  otázky pomocou modelu 'text-embedding-3-large'\n",
    "    response1 = openai.Embedding.create(\n",
    "            model=\"text-embedding-3-large\",  \n",
    "            input=otazka1\n",
    "        )\n",
    "    # Konvertuje odpoveď na pole numpy\n",
    "    embedding1=np.array(response1['data'][0]['embedding'])\n",
    "    \n",
    "\n",
    "    response2 = openai.Embedding.create(\n",
    "            model=\"text-embedding-3-large\",  \n",
    "            input=otazka2\n",
    "        )\n",
    "    embedding2=np.array(response2['data'][0]['embedding'])\n",
    "    # Preusporiada embeddings na formát potrebný pre výpočet podobnosti\n",
    "    embedding1 = embedding1.reshape(1, -1)\n",
    "    embedding2 = embedding2.reshape(1, -1)\n",
    "\n",
    "    # Vypočíta kosínusovú podobnosť medzi dvoma embeddings\n",
    "    similarity_score = cosine_similarity(embedding1, embedding2)\n",
    "    return similarity_score[0][0]\n",
    "\n",
    "\n",
    "def count_words(text):\n",
    "    words = re.findall(r'\\w+', text)  # Use regular expression to find all words\n",
    "    return len(words), words \n",
    "\n",
    "\n",
    "#Táto funkcia vypočíta podobnosť dvoch textov tak, že ich prevedie na vektory TF-IDF a potom vypočíta kosínusovú podobnosť medzi týmito vektormi. \n",
    "def custom_similarity_metric(ocakavana_odpoved, vytvorena_odpoved):\n",
    "    # Vytvorenie TF-IDF vektorizátorov pre očakávanú a vytvorenú odpoveď\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([ocakavana_odpoved, vytvorena_odpoved])\n",
    "\n",
    "    # Výpočet kosínusovej podobnosti medzi vektormi TF-IDF\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Kosínusová podobnosť pre konkrétny pár odpovedí\n",
    "    custom_similarity_score = similarity_matrix[0, 1]\n",
    "\n",
    "    return custom_similarity_score\n",
    "\n",
    "def calculate_similarity(embedding1, embedding2):\n",
    "    embedding1 = np.array(embedding1, dtype=np.float32)\n",
    "    embedding2 = np.array(embedding2, dtype=np.float32)\n",
    "\n",
    "    # Calculate cosine similarity between two embeddings\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "\n",
    "    # Check for zero division to avoid runtime warnings\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    return similarity\n",
    "\n",
    "#funckia na najdenie najrlevantnejsieho dotazu v datasete pre model Gemini\n",
    "def find_best_passage(query, dataframe):\n",
    "        model='models/embedding-001'\n",
    "        \"\"\"\n",
    "        Compute the distances between the query and each document in the dataframe\n",
    "        using the dot product.\n",
    "        \"\"\"\n",
    "        query_embedding = genai.embed_content(model=model,\n",
    "                                                content=query,\n",
    "                                                task_type=\"retrieval_query\")\n",
    "        dot_products = np.dot(np.stack(dataframe['Embeddings']), query_embedding[\"embedding\"])\n",
    "        idx = np.argmax(dot_products)\n",
    "        return dataframe.iloc[idx]['answers'] # Return text from index with max value\n",
    "\n",
    "\n",
    "#funkcia na vytovrenie \"promptu\" pre model gemini ktora urucje insturkcie pre model,otazku od pouzivatela a najdeny text ktory sa pouzije ako kontext\n",
    "def make_prompt(query, relevant_passage):\n",
    "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "  prompt = textwrap.dedent(\"\"\"si pomocnik ktory pomaha odpovedat studentom ohladom studia.Informacie ziskaj z passage ktore je pridane \n",
    "  QUESTION: '{query}'\n",
    "  PASSAGE: '{relevant_passage}'\n",
    "\n",
    "    ANSWER:\n",
    "  \"\"\").format(query=query, relevant_passage=escaped)\n",
    "\n",
    "  return prompt\n",
    "\n",
    "#funkcia pre model GPT , ktora v prvej casti ulohy otazku pretransformuje na embdeddings a nasledne podla kosinusovje podobnosti hlada najrelevantnejsiu zhodu\n",
    "#po najdeni zhody sa vytvori zakladny prompt ktory sa posiela pomocou API na vygeneoravnie odpovede\n",
    "def custombased(text,temperature,gpt_model,top_p):\n",
    "    response = openai.Embedding.create(\n",
    "            model=\"text-embedding-3-large\",  \n",
    "            input=text\n",
    "        )\n",
    "    question_embedding=response['data'][0]['embedding']\n",
    "\n",
    "\n",
    "    best_match = None\n",
    "    best_similarity = 0.0\n",
    "\n",
    "    for index, row in openai_embd.iterrows():\n",
    "            entry_embedding = row['embedding']   \n",
    "        \n",
    "            similarity = calculate_similarity(question_embedding, entry_embedding)\n",
    "\n",
    "\n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_match=row['answers']\n",
    "                \n",
    "    #print(best_match)\n",
    "                \n",
    "\n",
    "    query = f\"\"\"Pouzi dole priradeny clanok k odpovedi na otazku , ak nevies odpoved odpoved \"Nemam dostatok informaciu na tuto otazku\"  \"\n",
    "\n",
    "            clanok:\n",
    "            \\\"\\\"\\\"\n",
    "            {best_match}\n",
    "            \\\"\\\"\\\"\n",
    "\n",
    "            Otazka: {text}\"\"\"\n",
    "    #print(query)\n",
    "    #conversation = [\n",
    "    #        {\"role\": \"system\", \"content\": \"Si Skolsky asistent na techncikej univerzite v kosiciach a mas pomoct studentom odpoved na otazky\"},\n",
    "    #        {\"role\": \"user\", \"content\": f\"Question: {query}\"}\n",
    "    #    ]\n",
    "\n",
    "\n",
    "    conversation = [\n",
    "            {\"role\": \"system\", \"content\": \"Si skolsky asistent ktory odpoveda studentom na otazky vygeneruj odpoved maximalne v dlzke 256 tokenov \"},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {text}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Context: Pouzi dole priradeny clanok k odpovedi na otazku  clanok:{best_match}\"}\n",
    "        ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=gpt_model,\n",
    "    messages=conversation,\n",
    "    max_tokens=500,\n",
    "    temperature=temperature,\n",
    "    top_p=top_p\n",
    "    \n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "    answer = response['choices'][0]['message']['content'].strip()\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "#funkcia ktora spravi vsetky potrebne kroky pre vygenerovanie dotazku pre Gemini\n",
    "def gemini_resp(query,temperature,top_p):\n",
    "    #mesure time of execution \n",
    "    generation_config = {\n",
    "    \"temperature\": temperature,\n",
    "    \"top_p\": top_p\n",
    "    }\n",
    "    passage =find_best_passage(query, gemini_embd)\n",
    "    #print(passage)\n",
    "    prompt = make_prompt(query, passage)\n",
    "    model = genai.GenerativeModel('models/gemini-pro')\n",
    "    answer = model.generate_content(prompt,generation_config=generation_config)\n",
    "    return answer.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nacitanie dat a nastavenie dolezitych casti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '#################################'\n",
    "genai.configure(api_key='#################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nacitanie Dat a transofmracie embdeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------CREATING GEMINI EMBEDDEDINGS--------------------------------\")\n",
    "#gemini_embd=gemini_embdeddings_create()\n",
    "gemini_embd=pd.read_csv('gemini_embdeddings.csv')\n",
    "gemini_embd['Embeddings'] = gemini_embd.Embeddings.apply(eval).apply(np.array)\n",
    "print(\"--------------------------------CREATING OPENAI EMBEDDEDINGS--------------------------------\")\n",
    "#openai_embd=openai_embedding_create()\n",
    "openai_embd=pd.read_csv('openai_embdeddings.csv')\n",
    "openai_embd['embedding'] = openai_embd.embedding.apply(eval).apply(np.array)\n",
    "print(\"--------------------------------CREATING EMBEDDEDINGS FINISHED--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Vlastnost  (Robustness to Noise)\n",
    "\n",
    "Funkcia test_robustness testuje robustnosť AI modelu tým, že simuluje, ako model reaguje na rôzne úrovne \"šumu\" alebo chýb v textových vstupoch. Šum môže zahŕňať preklepove chyby slová, čo je situácia, ktora sa môžu vyskytnúť pri skutočnom použití. Poďme prejsť kód krok za krokom:\n",
    "\n",
    "Definícia Funkcie test_robustness:\n",
    "Funkcia prijíma dva parametre: prompt (textový vstup, na ktorom sa má testovať robustnosť) a noise_levels (zoznam úrovní šumu, ktoré sa majú testovať).\n",
    "Pre každú úroveň šumu vo zozname noise_levels funkcia vytvára šumivý prompt pomocou funkcie add_noise a následne používa túto upravenú verziu ako vstup pre model.\n",
    "Generovanie \"Noisy Prompt\" cez Funkciu add_noise:\n",
    "    Funkcia add_noise prijíma prompt a noise_level ako vstupy.\n",
    "    noisy_prompt je konvertovaný na zoznam znakov, aby bolo možné jednoducho meniť jednotlivé znaky.\n",
    "Pre každý znak v prompt sa rozhoduje, či ho zmeniť alebo nie, závisí od pravdepodobnosti určenej noise_level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_robustness(prompt, noise_levels):\n",
    "    for noise_level in noise_levels:\n",
    "        noisy_prompt = add_noise(prompt, noise_level)\n",
    "        #print(noisy_prompt)\n",
    "        response = custombased(noisy_prompt,0,'gpt-4-0125-preview')\n",
    "        \n",
    "        print(f\"Noisy Prompt: {noisy_prompt}\")\n",
    "        print(f\"Response: {response}\\n\")\n",
    "        #return response\n",
    "\n",
    "def add_noise(prompt, noise_level):\n",
    "    noisy_prompt = list(prompt)\n",
    "    for i, char in enumerate(noisy_prompt):\n",
    "        if random.random() < noise_level:\n",
    "            # Add typographical errors or misspellings\n",
    "            if char.isalpha():\n",
    "                noisy_prompt[i] = random.choice([c for c in 'abcdefghijklmnopqrstuvwxyz'])\n",
    "\n",
    "            # Add word order changes (e.g., shuffling words)\n",
    "            elif char.isspace() and i > 0 and noisy_prompt[i - 1].isspace():\n",
    "                j = i + 1\n",
    "                while j < len(noisy_prompt) and not noisy_prompt[j].isspace():\n",
    "                    j += 1\n",
    "                word = noisy_prompt[i:j]\n",
    "                random.shuffle(word)\n",
    "                noisy_prompt[i:j] = word\n",
    "\n",
    "    return ''.join(noisy_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Aký je rozsah predmetu objavovanie znalostí v týždennom rozsahu?\"\n",
    "noise_levels = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50] \n",
    "test_robustness(prompt, noise_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variabilnost pri rovnakej otazke ale inej variancie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia ktora testuje variabilnost otazok a nasledne vypocita bert score a similirty score s ocakvanou odpovedou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variarity(questions,expected_answer):\n",
    "    for question in questions:\n",
    "        response = custombased(question,0,'gpt-4-0125-preview')\n",
    "        #print(response)\n",
    "        similirity_score=create_embdeddings_similarity(response,expected_answer)\n",
    "        bert_scr=bert_score(response,expected_answer)\n",
    "        print (f\"similirity_score :{similirity_score} , bert score: {bert_scr}\")\n",
    "\n",
    "expected_answer='Rozsah predmetu objavovanie znalostí je týždenne 2 hodiny prednášok, 1 hodina laboratórneho cvičenia a 1 hodina projektovej práce.'\n",
    "questions = [\n",
    "    \"Aký je rozsah predmetu objavovanie znalostí v týždennom rozsahu?\",\n",
    "    \"opis predmet objavovanie znalosti\",\n",
    "    \"Koľko hodín v týždni je venovaných objavovaniu znalostí?\",\n",
    "    \"Aký časový rozsah pokrýva predmet objavovanie znalostí v jednom týždni?\",\n",
    "    \"Koľko času treba venovať objavovaniu znalostí počas jedného týždňa?\",\n",
    "    \"V akom časovom rozsahu sa venujeme objavovaniu znalostí každý týždeň?\",\n",
    "    \"Ako dlho trvá predmet objavovanie znalostí každý týždeň?\",\n",
    "]\n",
    "check_variarity(questions,expected_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia na vypocitanie efektu temperatue na generovanu odpoved, vypocet skore funguje rovnako ako vo funkcii check_variarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_effect(question,expected_answer,temperature_list):\n",
    "    for temperature in temperature_list:\n",
    "        response = custombased(question,temperature,'gpt-4-turbo-preview',0.5)\n",
    "        #print(response)\n",
    "        gpt_word_count, gpt_words = count_words(response)\n",
    "        \n",
    "        similirity_score=create_embdeddings_similarity(response,expected_answer)\n",
    "        bert_scr=bert_score(response,expected_answer)\n",
    "        print (f\"temperature:{temperature} similirity score:{similirity_score} bert score:{bert_scr},gpt_word_count:{gpt_word_count}\")\n",
    "expected_answer='Hlavnou anotáciou predmetu je prehĺbenie znalostí v oblasti objavovania znalostí a dolovania v dátach, proces objavovania znalostí, podrobná náplň jednotlivých fáz tohto procesu podľa metodiky CRISP-DM, metódy dolovania v dátach a ich rozdelenie, prediktívne dolovanie v dátach, metriky pre meranie podobnosti a vzdialenosti a ďalšie súvisiace témy.'\n",
    "temperature_list=[0,0.1,0.2]\n",
    "question=\"Aká je hlavná anotácia predmetu objavovanie znalostí?\"\n",
    "temperature_effect(question,expected_answer,temperature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia na porovanie modelov, nasledne vygenerovane odpovede sa porovnaju s ocakavanym vystupom a porovna sa ich podobnost a kvalita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(question,expected_answer,temperature,gpt_model):\n",
    "    for model in gpt_model:\n",
    "        response = custombased(question,temperature,model)\n",
    "        #print(response)\n",
    "        \n",
    "        similirity_score=create_embdeddings_similarity(response,expected_answer)\n",
    "        bert_scr=bert_score(response,expected_answer)\n",
    "        print (f\"model name:{model} similirity score:{similirity_score} bert score:{bert_scr}\")\n",
    "\n",
    "expected_answer='Hlavnou anotáciou predmetu je prehĺbenie znalostí v oblasti objavovania znalostí a dolovania v dátach, proces objavovania znalostí, podrobná náplň jednotlivých fáz tohto procesu podľa metodiky CRISP-DM, metódy dolovania v dátach a ich rozdelenie, prediktívne dolovanie v dátach, metriky pre meranie podobnosti a vzdialenosti a ďalšie súvisiace témy.'\n",
    "question=\"Aká je hlavná anotácia predmetu objavovanie znalostí?\"\n",
    "gpt_model=['gpt-4-0125-preview','gpt-4-turbo-preview','gpt-4-1106-preview','gpt-4','gpt-4-0613','gpt-3.5-turbo-0125','gpt-3.5-turbo','gpt-3.5-turbo-1106']\n",
    "compare_models(question,expected_answer,0,gpt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia na vygenerovanie rozdielnych kombinaici parametrov temperature a top_p, nasledne sa vypocita kvalita a skore odpovede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_answer='Hlavnou anotáciou predmetu je prehĺbenie znalostí v oblasti objavovania znalostí a dolovania v dátach, proces objavovania znalostí, podrobná náplň jednotlivých fáz tohto procesu podľa metodiky CRISP-DM, metódy dolovania v dátach a ich rozdelenie, prediktívne dolovanie v dátach, metriky pre meranie podobnosti a vzdialenosti a ďalšie súvisiace témy.'\n",
    "question=\"Aká je hlavná anotácia predmetu objavovanie znalostí?\"\n",
    "\n",
    "def create_questions():\n",
    "    temperature_list = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]\n",
    "    top_p_list = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    \n",
    "    # Create an empty list to store dictionaries\n",
    "    data = []\n",
    "\n",
    "    for temperature in temperature_list:\n",
    "        for top_p in top_p_list:\n",
    "            print(f\"tempreture:{temperature}, top_p:{top_p}\")\n",
    "            gpt_response = custombased(question, temperature, 'gpt-4-turbo-preview', top_p)\n",
    "            gemini_response = gemini_resp(question, temperature, top_p)\n",
    "            gpt_similarity_score = create_embdeddings_similarity(gpt_response, expected_answer)\n",
    "            gpt_bert_score = bert_score(gpt_response, expected_answer)\n",
    "            gemini_similarity_score = create_embdeddings_similarity(gemini_response, expected_answer)\n",
    "            gemini_bert_score = bert_score(gemini_response, expected_answer)\n",
    "            \n",
    "            # Count words and get word list for each answer\n",
    "            gpt_word_count, gpt_words = count_words(gpt_response)\n",
    "            gemini_word_count, gemini_words = count_words(gemini_response)\n",
    "            \n",
    "            # Append GPT results to the list\n",
    "            data.append({'model': 'GPT',\n",
    "                         'temperature': temperature,\n",
    "                         'top_p': top_p,\n",
    "                         'model_answer': gpt_response,\n",
    "                         'expected_answer': expected_answer,\n",
    "                         'similarity_score': gpt_similarity_score,\n",
    "                         'bert_score': gpt_bert_score,\n",
    "                         'word_count': gpt_word_count\n",
    "                         })\n",
    "            \n",
    "            # Append Gemini results to the list\n",
    "            data.append({'model': 'Gemini',\n",
    "                         'temperature': temperature,\n",
    "                         'top_p': top_p,\n",
    "                         'model_answer': gemini_response,\n",
    "                         'expected_answer': expected_answer,\n",
    "                         'similarity_score': gemini_similarity_score,\n",
    "                         'bert_score': gemini_bert_score,\n",
    "                         'word_count': gemini_word_count\n",
    "                         })\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('model_responses.csv', index=False)\n",
    "\n",
    "# Call the function to create the database\n",
    "create_questions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
